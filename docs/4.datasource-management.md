# ✅ FXバックテスト用 データソース管理 要件定義書

---

## 1. 🎯 概要と目的

FXバックテストシステムにおいて、**多様な形式の市場データ（tick, OHLC）を統一的に管理し、スムーズに提供できるデータ基盤を構築する**ことを目的とする。

- DukasCopy、MT4/MT5、カスタムアップロードなど様々なデータソース形式に対応
- データのチャンク管理、バージョン管理、スケジュール取得、上位足自動生成を一元的に実現
- 小規模構成（単一マシン）で動作可能な簡易アーキテクチャを採用

---

## 2. 📦 データソース管理

### 属性
| 項目 | 内容 |
|------|------|
| 名前 | 任意の識別名 |
| 通貨ペア | 例: `EURUSD` |
| 時間足 | 例: `tick`, `1m`, `5m`, `1h`, `1d` |
| データ形式 | `tick` or `ohlc` |
| ボリューム種別 | `none`, `actual`, `tick` |
| ソース種別 | `dukascopy`, `mt4`, `mt5`, `custom_upload` |
| 有効フラグ | 管理対象として有効か |

---

## 3. 📁 チャンク・バージョン管理

### チャンク単位
| 時間足 | チャンク範囲 |
|--------|--------------|
| tick, <=1m | 1時間単位 |
| >1m         | 1日単位 |

### バージョンと履歴
- 各チャンクにバージョン番号を付与
- 古いバージョンは物理削除は行わず、無効化（論理削除）
- アップロード履歴を `upload_history` テーブルに記録

### アップロード時のチャンクマージ
- 時間重複や隣接する既存チャンクとマージを実施
- 新しいチャンクに再構成し、古いものは `is_active = false` に更新

---

## 4. 🧩 上位時間足自動生成

### 概要
- 下位足（tick, 1mなど）から5m, 1h, 1dなどの上位足を自動的に生成
- 対象の上位時間足は事前定義 or 設定により決定

### 不完全データの判定
- チャンク内のデータ数が **想定本数の90%未満** の場合、`is_complete = false` として未完了扱い
- 判定ロジックは `completeness_ratio` に記録

---

## 5. 🗑️ チャンク削除（論理削除）

- チャンク単位で削除可能（`is_active = false`）
- `GET /chunks`, `GET /stream` などの取得系APIでは `is_active = true` のみ対象とする
- バージョン履歴は削除せず保持

---

## 6. 📤 データアップロードと履歴

### アップロード
- 管理画面またはAPIからのCSV/JSON形式アップロードに対応
- 同時間足/通貨ペアの重複チェックとマージを自動で行う

### 履歴記録
- `upload_history` にファイル名、ユーザー、日時、結果などを保存

---

## 7. 📅 スケジューラー（簡易構成）

### 実行方式
| 項目 | 内容 |
|------|------|
| 実装 | Python常駐プロセス（例：APScheduler） |
| 実行間隔 | 1分おきに `data_source_schedule` をポーリング |
| 排他制御 | `is_running` フラグまたはロックで制御 |
| ジョブ内容 | データ取得 → チャンク保存 → 上位足生成 → 不完全チャンク再試行 |
| ログ | DBまたはファイルに記録（実行日時、成功可否など） |

---

## 8. 🧩 API設計案

| メソッド | パス | 概要 |
|----------|------|------|
| GET | `/data-sources` | データソース一覧取得 |
| POST | `/data-sources` | データソース新規登録 |
| GET | `/data-sources/{id}` | データソース詳細取得 |
| DELETE | `/data-sources/{id}` | 論理削除 |
| POST | `/data-sources/{id}/upload` | 手動アップロード |
| GET | `/data-sources/{id}/histories` | アップロード履歴取得 |
| GET | `/data-sources/{id}/chunks` | チャンク一覧取得（`?complete_only=true` 対応） |
| GET | `/data-sources/{id}/chunks/{chunk_id}/download` | チャンクのダウンロード |
| DELETE | `/data-sources/{id}/chunks/{chunk_id}` | チャンクの論理削除 |
| PATCH | `/data-sources/{id}/schedule` | スケジュール設定更新 |
| GET | `/data-sources/{id}/schedule` | スケジュール設定取得 |
| POST | `/data-sources/{id}/chunks/{chunk_id}/regenerate` | チャンク手動再生成（保守用） |
| GET | `/data-sources/{id}/stream?from=...&to=...&format=csv|json` | 指定期間のデータ取得 |

---

## 9. 🧱 データベース設計（主要テーブル）

### `data_chunk`

| カラム | 型 | 内容 |
|--------|----|------|
| id | UUID | 主キー |
| data_source_id | UUID | 外部キー |
| start_time / end_time | datetime | チャンク期間 |
| version | int | バージョン番号 |
| is_complete | bool | 完全データか |
| completeness_ratio | float | 実データ割合 |
| is_active | bool | 有効フラグ（論理削除用） |
| file_path | str | ストレージ上のファイルパス |
| format | str | `tick` / `ohlc` |
| volume_type | str | `none` / `actual` / `tick` |
| size | int | バイト単位のファイルサイズ |

---

### `data_source_schedule`

| カラム | 型 | 内容 |
|--------|----|------|
| id | UUID | 主キー |
| data_source_id | UUID | 外部キー |
| enabled | bool | 実行フラグ |
| interval_type | str | `daily`, `weekly` など |
| run_at | time | 実行時刻（UTC） |
| last_run_at | datetime | 最終実行日時 |
| next_run_at | datetime | 次回実行予定日時 |

---

### `upload_history`

| カラム | 型 | 内容 |
|--------|----|------|
| id | UUID | 主キー |
| data_source_id | UUID | 外部キー |
| uploaded_by | str | 実行ユーザー or システム名 |
| uploaded_at | datetime | アップロード日時 |
| file_name | str | 元ファイル名 |
| version | int | 対応バージョン番号 |

---

## 🔚 今後の拡張余地（Optional）

- S3やBlob Storageとの連携による大規模データ対応
- 複数マシン環境でのジョブ分散（将来的にCeleryなど導入可能）
- データ品質の可視化（欠損率、異常値など）
